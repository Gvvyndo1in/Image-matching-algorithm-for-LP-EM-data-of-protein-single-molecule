{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80964680",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T07:06:36.064155Z",
     "start_time": "2022-07-03T07:06:33.787192Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import cv2 as cv\n",
    "import imageio\n",
    "from scipy import spatial\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "198e254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_quat(fi='cffk-orientation-dc8bb42/data/c48n9.quat'):\n",
    "    pdb=open(fi,'r')\n",
    "    lines=pdb.readlines()\n",
    "    quats=[]\n",
    "    for line in lines[4:]:\n",
    "        quat=np.asarray([float(line[0:12]),\n",
    "                         float(line[13:25]),\n",
    "                         float(line[26:38]),\n",
    "                         float(line[39:51])])\n",
    "        quats.append(quat)\n",
    "    return quats\n",
    "def rotpos(pos,quat=[1,0,0,0],origin=torch.tensor([0,0,0])):   \n",
    "    pos_rot=torch.mm(pos-origin,quat2mat(quat))\n",
    "    pos_rot=pos_rot+origin\n",
    "    return pos_rot\n",
    "def proj(pos,weight,drift,resolution,size,epsilon=1):\n",
    "    pic_i=torch.zeros(size,size)\n",
    "    atom_x=torch.tensor((pos[:,0]+drift[0])/resolution,dtype=torch.int32)#.type(torch.ShortTensor)\n",
    "    atom_y=torch.tensor((pos[:,1]+drift[1])/resolution,dtype=torch.int32)#.type(torch.ShortTensor)\n",
    "    for i in range(pos.shape[0]):\n",
    "        pic_i[atom_y[i],atom_x[i]]+=weight[i]\n",
    "    return (pic_i+epsilon).log()\n",
    "def genlib(pdblib='GAPRPDB',outdir='',\n",
    "           quatfile='lib/c48u27.quat',edge=1,resolution=3.7,iscg=0,libmol='lib/mol.csv',size=0,level=50):\n",
    "    rot=read_quat(quatfile)\n",
    "    lib={'pdb':[],'q':[],'pic':[]}\n",
    "    datalist=[]\n",
    "    maxdist=0\n",
    "    for npdb in os.listdir(pdblib):\n",
    "        pdb=readpdb(pdblib+'/'+npdb,iscg=iscg,libfile=libmol)\n",
    "        pos=torch.tensor(np.asarray(pdb)[:,4:7].astype('float32'))\n",
    "        origin=torch.tensor([(pdb.x*pdb.weight).sum()/pdb.weight.sum(),\n",
    "                             (pdb.y*pdb.weight).sum()/pdb.weight.sum(),\n",
    "                             (pdb.z*pdb.weight).sum()/pdb.weight.sum()])\n",
    "        pos=pos-origin\n",
    "        maxdist=max((pos*pos).sum(axis=1).max().sqrt(),maxdist)\n",
    "        weight=torch.tensor(np.asarray(pdb)[:,7].astype('float32'))\n",
    "        datalist.append((pos,weight,npdb))\n",
    "    if size==0:\n",
    "        size=1+int(2*maxdist/resolution)\n",
    "    drift_ini=torch.tensor([size*resolution/2,size*resolution/2,size*resolution/2])\n",
    "    for data in datalist:\n",
    "        pos=data[0]\n",
    "        weight=data[1]\n",
    "        npdb=data[2]\n",
    "        for i in tqdm(range(len(rot))):\n",
    "#        for i in range(len(rot)):\n",
    "            pos_rot=rotpos(pos,rot[i])\n",
    "            pic=proj(pos_rot,weight,drift_ini,resolution,size)\n",
    "#            ori=[int((size[0]-mat.shape[0])/2),int((size[1]-mat.shape[1])/2)]\n",
    "            lib['pdb'].append(npdb)\n",
    "            lib['q'].append(rot[i])\n",
    "            lib['pic'].append(pic.numpy())\n",
    "    lib=pd.DataFrame(lib)\n",
    "    if outdir!='':\n",
    "        os.mkdir(outdir)\n",
    "        for i in lib.index:\n",
    "#            print(lib.pic[i].max())\n",
    "            img=np.zeros(size,size,3)\n",
    "            cv.imwrite(outdir+'/'+str(i)+'.png',(lib.pic[i]*level).astype('uint8'))\n",
    "            outpic=cv.applyColorMap(cv.imread(outdir+'/'+str(i)+'.png'),cv.COLORMAP_AUTUMN)\n",
    "            cv.imwrite(outdir+'/'+str(i)+'.png',outpic)\n",
    "    return lib,size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ec9b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_Morph_parameter(lib,kernalsize_filter=(5,5),thresh=2.5,appsize=20,cviter=1):\n",
    "    thresh_area=[999,0]\n",
    "    thresh_dist=[10,0]\n",
    "    circle=0\n",
    "    liblist=[]\n",
    "    for i in lib.index:\n",
    "#        pic=lib.pic[i]+lib.pic[i].min()\n",
    "#        projpic=pic*255/(pic.max())\n",
    "        bi_gray=np.zeros(lib.pic[i].shape)\n",
    "        bi_gray[lib.pic[i]>thresh]=255\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (3, 3))\n",
    "        bi_gray = cv.morphologyEx(bi_gray, cv.MORPH_CLOSE, kernel,iterations=cviter)\n",
    "        bi_gray = cv.morphologyEx(bi_gray, cv.MORPH_OPEN, kernel,iterations=cviter)\n",
    "        contours, hierarchy = cv.findContours(bi_gray.astype('uint8'), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        largest=0\n",
    "#        print(i)\n",
    "        for c, contour in enumerate(contours):\n",
    "            Area = cv.contourArea(contour)\n",
    "#            print(c,Area)\n",
    "            if Area>=largest:\n",
    "                largest=Area\n",
    "#                circle=cv.arcLength(contour, True)\n",
    "                contour_r=contour.reshape(contour.size//2,2)\n",
    "                maxdist=spatial.distance_matrix(contour_r, contour_r).max()\n",
    "#        liblist.append([largest,circle])\n",
    "        liblist.append([largest,maxdist])\n",
    "#        print(largest,circle*circle/(largest*4*3.1415926))\n",
    "#        maxcd=circle*circle/(largest*4*3.1415926)\n",
    "    liblist=np.asarray(liblist)\n",
    "    thresh_contour = liblist[spatial.ConvexHull(liblist).vertices]\n",
    "    return thresh_contour\n",
    "def Extract_Protein(\n",
    "    picdir,thresh_contour,\n",
    "    outdir='test',\n",
    "    cviter=3,\n",
    "    picave=3,\n",
    "    diiter=3,\n",
    "    thresh_adt=0.35,\n",
    "    thresh_pick=0.1,\n",
    "    kernalsize_adt=(25,25),\n",
    "    kernalsize_filter=(5,5),\n",
    "    avekernal=[0.25,0.5,0.25],\n",
    "    listthresh=30\n",
    "    ):\n",
    "    os.mkdir(outdir+'/binary')\n",
    "    os.mkdir(outdir+'/ori')\n",
    "#################################################################################\n",
    "    extended_contour=np.zeros((thresh_contour.shape[0]+1,thresh_contour.shape[1]))\n",
    "    extended_contour[:-1,:]=thresh_contour\n",
    "    avekernal=np.asarray(avekernal)\n",
    "    avecenter=avekernal.argmax()\n",
    "    dirlist=os.listdir(picdir)\n",
    "    pinserie=[]\n",
    "    contourlist=[]\n",
    "    print(thresh_contour)\n",
    "    hullarea=spatial.ConvexHull(thresh_contour).volume\n",
    "    for i,p in enumerate(dirlist):\n",
    "        pinframe=[i+avecenter,dirlist[i+avecenter]]\n",
    "        if i>=(len(dirlist)-picave):\n",
    "            break\n",
    "        ave=0\n",
    "        ori=cv.imread(picdir+'/'+dirlist[i+avecenter],flags=cv.CV_8U)\n",
    "        for j in range(picave):\n",
    "            ave=ave+cv.imread(picdir+'/'+dirlist[i+j],flags=cv.CV_8U)*avekernal[j]\n",
    "        burr=cv.GaussianBlur(ave.astype('uint8'), kernalsize_filter, 0)\n",
    "        bi_gray= (255-AdaptiveThresh(burr,kernalsize_adt,thresh_adt)).astype('uint8')\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (3, 3))\n",
    "        bi_gray = cv.morphologyEx(bi_gray, cv.MORPH_OPEN, kernel,iterations=cviter)\n",
    "        bi_gray = cv.morphologyEx(bi_gray, cv.MORPH_CLOSE, kernel,iterations=cviter)\n",
    "        cv.imwrite(outdir+'/binary/'+dirlist[i+avecenter],bi_gray)\n",
    "        contours, hierarchy = cv.findContours(bi_gray.astype('uint8'), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        outpic=ave.copy()\n",
    "#        tempmask=np.zeros(ave.shape,dtype='uint8')\n",
    "        pcounts=0\n",
    "        for c, contour in enumerate(contours):\n",
    "            # print(i)\n",
    "#            print(contour)\n",
    "            Area = cv.contourArea(contour)\n",
    "            if Area==0:\n",
    "                continue\n",
    "#            circle=cv.arcLength(contour, True)\n",
    "            contour_r=contour.reshape(contour.size//2,2)\n",
    "            maxdist=spatial.distance_matrix(contour_r, contour_r).max()\n",
    "            extended_contour[-1]=np.asarray([Area,maxdist])\n",
    "            para_pick=spatial.ConvexHull(extended_contour).volume-hullarea\n",
    "            if Area>=50:\n",
    "                contourlist.append([p,c,Area,maxdist,contour.mean(axis=0)[0][0],contour.mean(axis=0)[0][1],para_pick])\n",
    "            if para_pick<thresh_pick:\n",
    "                cv.drawContours(ori,contours,c,255,1)\n",
    "                pinframe.append([contour.mean(axis=0)[0],contour])\n",
    "                pcounts+=1\n",
    "        pinserie.append(pinframe)\n",
    "#        print('found ',pcounts,' in pic ',dirlist[i+avecenter])    \n",
    "#        tempmask=cv.dilate(tempmask,kernel=kernel,iterations=3)\n",
    "#        masked=(tempmask/255*(255-cv.imread(picdir+'/'+dirlist[i+avecenter],flags=cv.CV_8U))).astype('uint8')\n",
    "        cv.imwrite(outdir+'/ori/'+dirlist[i+avecenter],ori)\n",
    "    pd.DataFrame(contourlist,columns=['name','id','area','circle','x','y','para_dist']).to_csv(outdir+'/contour.csv')\n",
    "    return pinserie\n",
    "def Particle_clustering(pinserie,minobserve,maxmissing=15,maxdrift=7.0):\n",
    "    plist=[]\n",
    "    protein=[]\n",
    "#pinserie saved as [[frame,filename,[center1,contour1],[center2,contour2]...]...]\n",
    "#clustered protein saved as [[frame1,filename1,center1,contour1], [frame2,filename2,center2,contour2], [frame3,filename3,center3,contour3]...] \n",
    "    while len(pinserie)>0:\n",
    "#        print(len(pinserie),pinserie[0],len(pinserie[0]))\n",
    "        while len(pinserie[0])==2:\n",
    "            pinserie.pop(0)\n",
    "            if len(pinserie)==0:\n",
    "                if len(protein)>=minobserve:\n",
    "                    print('protein ',len(plist),'detected in ',len(protein),' frames')\n",
    "                    plist.append(protein)\n",
    "#                print('all protein detected')\n",
    "                return plist\n",
    "        protein=[[pinserie[0][0],pinserie[0][1],pinserie[0][2][0],pinserie[0][2][1]]]\n",
    "        print('protein',len(plist),' detected at frame ',protein[-1][0],' centered at ',protein[-1][2])\n",
    "        pinserie[0].pop(2)\n",
    "        missedframe=1\n",
    "        for pl in pinserie[1:]:\n",
    "#            print(pl[0],len(pl))\n",
    "            for pi in range(2,len(pl)):\n",
    "#protein drift less than sqrt(maxdrift*missingframes) been considered as series\n",
    "                if ((protein[-1][2]-pl[pi][0])**2).sum() <missedframe*maxdrift*maxdrift:\n",
    "#                    print('find protein',len(plist),' at frame ',pl[0],'centered at',pl[pi][0],'after ',missedframe,' frames')\n",
    "                    protein.append([pl[0],pl[1],pl[pi][0],pl[pi][1]])\n",
    "                    pl.pop(pi)\n",
    "                    missedframe=0\n",
    "                    break\n",
    "            missedframe+=1\n",
    "            if missedframe>=maxmissing:\n",
    "                break\n",
    "        if len(protein)>=minobserve:\n",
    "            print('protein ',len(plist),'detected in ',len(protein),' frames')\n",
    "            plist.append(protein)\n",
    "    return plist\n",
    "def Gen_picked_pic(plist,dirin,outdir,\n",
    "                   kernel=cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5)),dilate_iter=3,picsize=[35,35],\n",
    "                   debug=True):\n",
    "    count=0\n",
    "    dirlist=[]\n",
    "    drifts=[]\n",
    "    for i in plist:\n",
    "        count+=1\n",
    "        os.mkdir(outdir+'/protein_'+str(count))\n",
    "        os.mkdir(outdir+'/ori_'+str(count))\n",
    "#        print(os.system('mkdir '+tempdir+'_'+str(count)),'mkdir '+tempdir+'_'+str(count))\n",
    "        dirlist.append(outdir+'/protein_'+str(count))\n",
    "        drift=[]\n",
    "        for c in i:\n",
    "#            print(c[1],c[3])\n",
    "            ori_pic=cv.imread(dirin+'/'+c[1],flags=cv.CV_8U)\n",
    "            mask=np.zeros(ori_pic.shape,dtype='uint8')\n",
    "            cv.drawContours(mask,(c[3],),0,255,cv.FILLED)\n",
    "            mask=cv.dilate(mask,kernel=kernel,iterations=dilate_iter)\n",
    "            masked=(mask/255*(255-ori_pic))\n",
    "            masked[masked==0]=255-ori_pic.mean()\n",
    "     #       masked=masked.astype('uint8')\n",
    "            pos=[int(c[2][0]),int(c[2][1])]\n",
    "            cutted=masked[max(0,pos[1]-picsize[1]):min(ori_pic.shape[1],pos[1]+picsize[1]),max(0,pos[0]-picsize[0]):min(ori_pic.shape[0],pos[0]+picsize[0])].astype('uint8')\n",
    "            cutted_ori=ori_pic[max(0,pos[1]-picsize[1]):min(ori_pic.shape[1],pos[1]+picsize[1]),max(0,pos[0]-picsize[0]):min(ori_pic.shape[0],pos[0]+picsize[0])].astype('uint8')\n",
    "            cv.drawContours(ori_pic,(c[3],),0,255,1)\n",
    "            drift.append((max(0,pos[1]-picsize[1]),max(0,pos[0]-picsize[0])))\n",
    "            cv.imwrite(outdir+'/ori_'+str(count)+'/'+c[1],cutted_ori)\n",
    "            cv.imwrite(outdir+'/protein_'+str(count)+'/'+c[1],cutted)\n",
    "        drifts.append(drift)\n",
    "    return dirlist,drifts\n",
    "def cvmatch(lib,pic,drift,ori=0,r=10,method=cv.TM_CCOEFF_NORMED):\n",
    "#def cvmatch(lib,pic,ori=0,r=10,method=cv.TM_CCORR_NORMED):\n",
    "#def cvmatch(lib,pic,ori=0,r=10,method=cv.TM_CCORR):\n",
    "\n",
    "#    tempic=(mpimg.imread(pic).mean()-mpimg.imread(pic)).astype('uint8')\n",
    "#    inpic=cv.imread(pic,cv.CV_8U)[323:366,385:424].astype('float32')\n",
    "#    inpic=cv.imread(pic,cv.CV_8U)[270:372,425:517].astype('float32')\n",
    "    tempic=cv.imread(pic,cv.CV_8U).astype('float32')\n",
    "#    tempic=extract_protein(inpic)\n",
    "    bestfit=[0,0,0,0,0,0,0]\n",
    "    cvlib=lib\n",
    "    scores=[]\n",
    "    drifts=[]\n",
    "#    for p in lib:\n",
    "#        cvlib[p]=(lib[p].astype('float32'))\n",
    "    for p in cvlib.index:\n",
    "        i=cvlib.pic[p]\n",
    "        cmatch=cv.matchTemplate(tempic,i,method)\n",
    "        m=cmatch.argmax()\n",
    "        l=len(cmatch[0])\n",
    "# normalized TMCCORR\n",
    "#        score=2*cmatch.max()/((i*i).sum()+(tempic[int(m//l):int(m//l)+i.shape[0],m%l:m%l+i.shape[1]]*tempic[int(m//l):int(m//l)+i.shape[0],m%l:m%l+i.shape[1]]).sum())\n",
    "        score=cmatch.max()\n",
    "        scores.append(score)\n",
    "        drifts.append([m%l+i.shape[1],int(m//l)+i.shape[0]])\n",
    "    return drifts,np.asarray(scores)\n",
    "def extract_best(scores,libshape,ntops=5):\n",
    "    score_t=scores.reshape(libshape[1],libshape[0])\n",
    "    output=[]\n",
    "    for pid,score_l in enumerate(score_t):\n",
    "        top_index=np.argpartition(score_l, -ntops)[-ntops:]\n",
    "        for i in top_index:\n",
    "            output.append([pid,i,score_l[i]])\n",
    "    return(np.asarray(output))\n",
    "def autosearch(picdir,template,\n",
    "               outdir='fitted',debug=True,\n",
    "               quatfile='lib/c48u27.quat',resolution=3.7,rf=10,pick=[],\n",
    "               libmol='lib/mol.csv',iscg=0,picsize=0,thresh_pick=0.01,\n",
    "               minobserve=100,thresh_adt=0.35,ntops=1):\n",
    "    dirlist=os.listdir(picdir)\n",
    "    os.mkdir(outdir)\n",
    "    if type(template)==str:\n",
    "        lib,size=genlib(template,quatfile,resolution=resolution,iscg=iscg,libmol=libmol,size=picsize)\n",
    "        picsize=[size,size]\n",
    "        print('lib generated')\n",
    "        thresh_contour=gen_Morph_parameter(lib)\n",
    "    elif type(template)==pd.DataFrame:\n",
    "        lib=template\n",
    "        print('use input lib')\n",
    "        picsize=lib.pic[0].shape\n",
    "        thresh_contour=gen_Morph_parameter(lib)\n",
    "    else:\n",
    "        raise ValueError('input lib must be a folder contains pdb files or a libary generated by genlib')\n",
    "    if len(pick)==3:\n",
    "#            thresh_contour=np.asarray([[pick[0]*pick[1]*np.pi/(4*resolution),max(pick[0],pick[1])],\n",
    "#                                       [pick[2]*pick[1]*np.pi/(4*resolution),max(pick[2],pick[1])],\n",
    "#                                       [pick[0]*pick[2]*np.pi/(4*resolution),max(pick[0],pick[2])],])/resolution\n",
    "            thresh_contour=np.asarray([[pick[0]*pick[1]/(resolution),np.sqrt(pick[0]*pick[0]+pick[1]*pick[1])],\n",
    "                                       [pick[2]*pick[1]/(resolution),np.sqrt(pick[2]*pick[2]+pick[1]*pick[1])],\n",
    "                                       [pick[0]*pick[2]/(resolution),np.sqrt(pick[0]*pick[0]+pick[2]*pick[2])],])/resolution\n",
    "            print('pick particles with length: ',template)\n",
    "    print('pick range generated')\n",
    "    pinserie=Extract_Protein(picdir,thresh_contour,outdir=outdir,thresh_adt=thresh_adt,thresh_pick=thresh_pick)\n",
    "    print('contours found')    \n",
    "    plist=Particle_clustering(pinserie,minobserve,maxmissing=30,maxdrift=7)\n",
    "    print('particle clustered')\n",
    "    picked_dirlist,drifts=Gen_picked_pic(plist,picdir,outdir=outdir,\n",
    "                                         kernel=cv.getStructuringElement(cv.MORPH_ELLIPSE, (3, 3)),dilate_iter=3,picsize=picsize)\n",
    "    print('picked picture generated')\n",
    "    summary=pd.DataFrame({'pic':[],'protein_id':[],'pdb':[],'score':[],'qr':[],'qi':[],'qj':[],'qk':[],'dx':[],'dy':[]},index=[])\n",
    "    pdblist=lib['pdb'].unique()\n",
    "    libshape=[int(len(lib)/len(pdblist)),len(pdblist)]\n",
    "    qlist=lib['q'][0:libshape[0]]\n",
    "    for pc,protein in enumerate(picked_dirlist):\n",
    "        fits={}\n",
    "        dirlist_pro=os.listdir(protein)\n",
    "        list_score=np.zeros([len(dirlist_pro),len(lib)])\n",
    "        for c,i in enumerate(dirlist_pro):\n",
    "            pic_summary=pd.DataFrame({'pic':[],'protein_id':[],'pdb':[],'score':[],'qr':[],'qi':[],'qj':[],'qk':[],'dx':[],'dy':[]},index=[])\n",
    "            drift,list_score[c]=cvmatch(lib,protein+'/'+i,drifts[pc][c])\n",
    "            outdata=extract_best(list_score[c],libshape,ntops)\n",
    "            for out in outdata:\n",
    "#               print(qlist[out[1]])\n",
    "#                for n in range(len(out)):\n",
    "#                print(out)\n",
    "                pic_summary=pic_summary.append(pd.DataFrame({'pic':c,'protein_id':pc,'pdb':pdblist[int(out[0])],'score':out[2],\n",
    "                                                     'qr':qlist[out[1]][0].item(),'qi':qlist[out[1]][1].item(),'qj':qlist[out[1]][2].item(),'qk':qlist[out[1]][3].item(),\n",
    "                                                     'dx':drift[int(out[0]*libshape[1]+out[1])][1],'dy':drift[int(out[0]*libshape[1]+out[1])][0]},index=[0]),ignore_index=True)\n",
    "#                print(outdata)\n",
    "            best_index=pic_summary.score.argmax()\n",
    "#            print(pic_summary.dx[best_index])\n",
    "            fit=[0,pic_summary.dx[best_index],pic_summary.dy[best_index],pic_summary.score[best_index],\n",
    "                 pic_summary.pdb[best_index]]\n",
    "            summary=summary.append(pic_summary,ignore_index=True)\n",
    "            fits[i]=fit\n",
    "            print('protein '+protein+' in picture',i,'is fitted as',fit[4],'fitted score:',fit[3])\n",
    "        makegif(fits,outdir+'/ori_'+str(pc+1),outdir+'/protein_'+str(pc+1),outdir+'/protein_'+str(pc+1)+'pics',picsize)\n",
    "        print('gif for protein '+str(pc+1)+' saved as '+outdir+'/protein_'+str(pc+1)+'movie.gif')\n",
    "        table_score=pd.DataFrame(list_score)\n",
    "        table_score.index=dirlist_pro\n",
    "        table_score.to_csv(outdir+'/protein_'+str(pc+1)+'.csv')\n",
    "#        makegif(0,outdir+'/ori_'+str(pc+1),outdir+'/protein_'+str(pc+1)+'ori.gif')\n",
    "    summary.to_csv(outdir+'/summary.csv')\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d75e3a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T07:06:36.080156Z",
     "start_time": "2022-07-03T07:06:36.067158Z"
    }
   },
   "outputs": [],
   "source": [
    "############ module I structure reading ##############\n",
    "### currently support: all-atom/sirah2 pdb libary\n",
    "def readpdb(fi='target.pdb',libfile='lib/mol.csv',iscg=False):\n",
    "    pdb=open(fi,'r')\n",
    "    index=[]\n",
    "    name=[]\n",
    "    resname=[]\n",
    "    chain=[]\n",
    "    resid=[]\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "    weight=[]\n",
    "    element=[]\n",
    "    lines=pdb.readlines()\n",
    "    weightdict={}\n",
    "    lib=pd.read_csv(libfile)\n",
    "    if iscg:\n",
    "        for i in lib.index:\n",
    "            weightdict[(lib.residue[i],lib.element[i])]=lib.electron[i]\n",
    "    else:\n",
    "        for i in lib.index:\n",
    "            weightdict[lib.element[i]]=lib.electron[i]\n",
    "    for line in lines:\n",
    "        if line[0:4] == 'ATOM':\n",
    "            index.append(int(line[6:11]))\n",
    "            n=line[12:16]\n",
    "            name.append(n.strip())\n",
    "            resname.append(line[17:20].strip())\n",
    "            resid.append(int(line[22:26]))\n",
    "            x.append(float(line[30:38]))\n",
    "            y.append(float(line[38:46]))\n",
    "            z.append(float(line[46:54]))\n",
    "            if len(line)<77 or line[76:78].strip()=='':\n",
    "                element.append(n.strip()[0])\n",
    "            else:\n",
    "                element.append(line[76:78].strip())\n",
    "            if iscg:\n",
    "                weight.append(weightdict[(resname[-1],name[-1])])\n",
    "            else:\n",
    "                weight.append(weightdict[element[-1]])\n",
    "#            charge.append(int(line[78:80]))\n",
    "    data=pd.DataFrame({\n",
    "        'series':index,\n",
    "        'name':name,\n",
    "        'resname':resname,\n",
    "        'resid':resid,\n",
    "        'x':x,\n",
    "        'y':y,\n",
    "        'z':z,\n",
    "        'weight':weight,\n",
    "        'element':element\n",
    "    })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fa66a66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T07:06:36.111157Z",
     "start_time": "2022-07-03T07:06:36.084157Z"
    }
   },
   "outputs": [],
   "source": [
    "############ module 0 math ##############\n",
    "#Taitâ€“Bryan angles https://en.wikipedia.org/wiki/Conversion_between_quaternions_and_Euler_angles\n",
    "#eular=np.asarray[phi,theta,psi]\n",
    "def eular2mat(eular):\n",
    "    se=np.sin(eular)\n",
    "    ce=np.cos(eular)\n",
    "    mat=np.asarray([[ ce[2]*ce[1]   ,-se[2]*ce[1]+ce[2]*se[1]*se[0]  , se[2]*se[0]+ce[2]*se[1]*ce[0]] ,\n",
    "                    [ se[2]*ce[1]   , ce[2]*ce[1]+se[2]*se[1]*se[0]  ,-ce[2]*se[0]+se[2]*se[1]*ce[0]] ,\n",
    "                    [       se[1]   ,                   ce[1]*se[0]  ,                   ce[1]*ce[0]] ])\n",
    "    return mat\n",
    "def read_quat(fi='cffk-orientation-dc8bb42/data/c48n9.quat'):\n",
    "    pdb=open(fi,'r')\n",
    "    lines=pdb.readlines()\n",
    "    quats=[]\n",
    "    for line in lines[4:]:\n",
    "        quat=np.asarray([float(line[0:12]),\n",
    "                         float(line[13:25]),\n",
    "                         float(line[26:38]),\n",
    "                         float(line[39:51])])\n",
    "        quats.append(quat)\n",
    "    return quats\n",
    "def gen_quater(libgrid='std60.csv',ang=5):#obsoleted\n",
    "    grids=pd.read_csv(libgrid)\n",
    "    theta=math.pi/ang\n",
    "    dtheta=math.pi/ang\n",
    "    quaterlist=[np.array([1,0,0,0])]\n",
    "    for i in range(0,ang):\n",
    "        s=math.sin(theta/2)\n",
    "        c=math.cos(theta/2)\n",
    "        for j in grids.index:\n",
    "            quaterlist.append(np.array([c,s*grids.i[j],s*grids.j[j],s*grids.k[j]]))\n",
    "        theta+=dtheta\n",
    "#    print(len(quaterlist),' quaterions generated')\n",
    "    return quaterlist\n",
    "def gen_quater_d(libgrid='std60.csv',ang=5):\n",
    "    grids=pd.read_csv(libgrid)\n",
    "    quaterlist=[np.array([1,0,0,0])]\n",
    "    s=math.sin(ang*np.pi/360)\n",
    "    c=math.cos(ang*np.pi/360)\n",
    "    for j in grids.index:\n",
    "        quaterlist.append(np.array([c,s*grids.i[j],s*grids.j[j],s*grids.k[j]]))\n",
    "#    print(len(quaterlist),' quaterions generated')\n",
    "    return quaterlist\n",
    "def eular2quater(eular):\n",
    "    se=np.sin(eular/2)\n",
    "    ce=np.cos(eular/2)\n",
    "    q=np.asarray([ce[0]*ce[1]*ce[2]+se[0]*se[1]*se[2],\n",
    "                  se[0]*ce[1]*ce[2]-ce[0]*se[1]*se[2],\n",
    "                  ce[0]*se[1]*ce[2]+se[0]*ce[1]*se[2],\n",
    "                  ce[0]*ce[1]*se[2]-se[0]*se[1]*ce[2]])\n",
    "    return q\n",
    "def quater2eular(q):\n",
    "    eular=np.asarray([np.arctan2(2*(q[0]*q[1]+q[2]*q[3],1-2*(q[1]*q[1]+q[2]*q[2]))),\n",
    "                      np.arcsin(2*(q[0]*q[2]-q[1]*q[3])),\n",
    "                      np.arctan2(2*(q[0]*q[3]+q[1]*q[2],1-2*(q[3]*q[3]+q[2]*q[2])))])\n",
    "    return eular\n",
    "def pearson(pica,picb):\n",
    "    pica_mean=torch.mean(pica)\n",
    "    picb_mean=torch.mean(picb)\n",
    "    cov=torch.mean(pica*picb)-pica_mean*picb_mean\n",
    "    pica_var=torch.mean(pica*pica)-pica_mean*pica_mean\n",
    "    picb_var=torch.mean(picb*picb)-picb_mean*picb_mean\n",
    "    loss=cov*cov/(pica_var*picb_var)\n",
    "    pearson=loss.sqrt()\n",
    "    return pearson\n",
    "def rotpos(pos,quat=[1,0,0,0],origin=torch.tensor([0,0,0])):   \n",
    "    pos_rot=torch.mm(pos-origin,quat2mat(quat))\n",
    "    pos_rot=pos_rot+origin\n",
    "    return pos_rot\n",
    "def quat2mat(q):\n",
    "#q=(qr,qi,qj,qk)\n",
    "#from qr=cos(theta/2) qi,qj,qk=sin(theta/2)*x,y,z \n",
    "    mat=torch.tensor([[1-2*q[2]*q[2]-2*q[3]*q[3],  2*(q[1]*q[2]-q[3]*q[0]),  2*(q[1]*q[3]+q[2]*q[0])],\n",
    "                      [  2*(q[1]*q[2]+q[3]*q[0]),1-2*q[1]*q[1]-2*q[3]*q[3],  2*(q[2]*q[3]-q[1]*q[0])],\n",
    "                      [  2*(q[1]*q[3]-q[2]*q[0]),  2*(q[2]*q[3]+q[1]*q[0]),1-2*q[1]*q[1]-2*q[2]*q[2]]],dtype=torch.float64)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3dae094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T07:06:36.143156Z",
     "start_time": "2022-07-03T07:06:36.114162Z"
    }
   },
   "outputs": [],
   "source": [
    "############ module II generate libaray ##############\n",
    "'''def pdb_trans(pdb,trans):\n",
    "#transform define as (psi,theta,phi,dx,dy)\n",
    "    trans_pdb=pdb.copy(deep=True)\n",
    "    pos=np.matmul(np.array(data)[:,4:7],eular2mat(trans[:3]))\n",
    "    pos[]\n",
    "    trans_pdb[:,4:7]\n",
    "    return trans_pdb'''\n",
    "def proj_sigmoid(pos,weight,drift,resolution,size,N=100,epsilon=1):\n",
    "    pic_i=torch.zeros(size,size)\n",
    "    atom_x=torch.tensor((pos[:,0]+drift[0])*N)\n",
    "    atom_y=torch.tensor((pos[:,1]+drift[1])*N)\n",
    "    d=resolution*N\n",
    "    for y in range(size):\n",
    "        for x in range(size):\n",
    "            pic_i[y,x]=((((atom_x-d*x).sigmoid()-(atom_x-d*(x+1)).sigmoid())*((atom_y-d*y).sigmoid()-(atom_y-d*(y+1)).sigmoid())*weight).sum()+epsilon).log()\n",
    "    return pic_i\n",
    "def proj(pos,weight,drift,resolution,size,epsilon=1):\n",
    "    pic_i=torch.zeros(size,size)\n",
    "    atom_x=torch.tensor((pos[:,0]+drift[0])/resolution,dtype=torch.int32)#.type(torch.ShortTensor)\n",
    "    atom_y=torch.tensor((pos[:,1]+drift[1])/resolution,dtype=torch.int32)#.type(torch.ShortTensor)\n",
    "    for i in range(pos.shape[0]):\n",
    "        pic_i[atom_y[i],atom_x[i]]+=weight[i]\n",
    "    return (pic_i+epsilon).log()\n",
    "def genlib(pdblib='GAPRPDB',outdir='',\n",
    "           quatfile='lib/c48u27.quat',edge=1,resolution=3.7,iscg=0,libmol='lib/mol.csv',size=0,level=50):\n",
    "    rot=read_quat(quatfile)\n",
    "    lib={'pdb':[],'q':[],'pic':[]}\n",
    "    datalist=[]\n",
    "    maxdist=0\n",
    "    for npdb in os.listdir(pdblib):\n",
    "        pdb=readpdb(pdblib+'/'+npdb,iscg=iscg,libfile=libmol)\n",
    "        pos=torch.tensor(np.asarray(pdb)[:,4:7].astype('float32'))\n",
    "        origin=torch.tensor([(pdb.x*pdb.weight).sum()/pdb.weight.sum(),\n",
    "                             (pdb.y*pdb.weight).sum()/pdb.weight.sum(),\n",
    "                             (pdb.z*pdb.weight).sum()/pdb.weight.sum()])\n",
    "        pos=pos-origin\n",
    "        maxdist=max((pos*pos).sum(axis=1).max().sqrt(),maxdist)\n",
    "        weight=torch.tensor(np.asarray(pdb)[:,7].astype('float32'))\n",
    "        datalist.append((pos,weight,npdb))\n",
    "    if size==0:\n",
    "        size=1+int(2*maxdist/resolution)\n",
    "    drift_ini=torch.tensor([size*resolution/2,size*resolution/2,size*resolution/2])\n",
    "    for data in datalist:\n",
    "        pos=data[0]\n",
    "        weight=data[1]\n",
    "        npdb=data[2]\n",
    "        for i in tqdm(range(len(rot))):\n",
    "#        for i in range(len(rot)):\n",
    "            pos_rot=rotpos(pos,rot[i])\n",
    "            pic=proj(pos_rot,weight,drift_ini,resolution,size)\n",
    "#            ori=[int((size[0]-mat.shape[0])/2),int((size[1]-mat.shape[1])/2)]\n",
    "            lib['pdb'].append(npdb)\n",
    "            lib['q'].append(rot[i])\n",
    "            lib['pic'].append(pic.numpy())\n",
    "    lib=pd.DataFrame(lib)\n",
    "    if outdir!='':\n",
    "        os.mkdir(outdir)\n",
    "        for i in lib.index:\n",
    "#            print(lib.pic[i].max())\n",
    "            img=np.zeros(size,size,3)\n",
    "            cv.imwrite(outdir+'/'+str(i)+'.png',(lib.pic[i]*level).astype('uint8'))\n",
    "            outpic=cv.applyColorMap(cv.imread(outdir+'/'+str(i)+'.png'),cv.COLORMAP_AUTUMN)\n",
    "            cv.imwrite(outdir+'/'+str(i)+'.png',outpic)\n",
    "    return lib,size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c95d59e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T07:06:36.983156Z",
     "start_time": "2022-07-03T07:06:36.864157Z"
    }
   },
   "outputs": [],
   "source": [
    "############ module I&III morphing ##############\n",
    "def AdaptiveThresh(I,winSize,ratio=0.15):\n",
    "    I_mean=cv.boxFilter(I,cv.CV_8U,winSize,borderType=cv.BORDER_REFLECT)\n",
    "    out=I-(1.0-ratio)*I_mean\n",
    "    out[out>=0]=255\n",
    "    out[out<0]=0\n",
    "    return out.astype(np.uint8)\n",
    "def gen_Morph_parameter(lib,kernalsize_filter=(5,5),thresh=2.5,appsize=20,cviter=1):\n",
    "    thresh_area=[999,0]\n",
    "    thresh_dist=[10,0]\n",
    "    circle=0\n",
    "    liblist=[]\n",
    "    for i in lib.index:\n",
    "#        pic=lib.pic[i]+lib.pic[i].min()\n",
    "#        projpic=pic*255/(pic.max())\n",
    "        bi_gray=np.zeros(lib.pic[i].shape)\n",
    "        bi_gray[lib.pic[i]>thresh]=255\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (3, 3))\n",
    "        bi_gray = cv.morphologyEx(bi_gray, cv.MORPH_CLOSE, kernel,iterations=cviter)\n",
    "        bi_gray = cv.morphologyEx(bi_gray, cv.MORPH_OPEN, kernel,iterations=cviter)\n",
    "        contours, hierarchy = cv.findContours(bi_gray.astype('uint8'), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        largest=0\n",
    "#        print(i)\n",
    "        for c, contour in enumerate(contours):\n",
    "            Area = cv.contourArea(contour)\n",
    "#            print(c,Area)\n",
    "            if Area>=largest:\n",
    "                largest=Area\n",
    "#                circle=cv.arcLength(contour, True)\n",
    "                contour_r=contour.reshape(contour.size//2,2)\n",
    "                maxdist=spatial.distance_matrix(contour_r, contour_r).max()\n",
    "#        liblist.append([largest,circle])\n",
    "        liblist.append([largest,maxdist])\n",
    "#        print(largest,circle*circle/(largest*4*3.1415926))\n",
    "#        maxcd=circle*circle/(largest*4*3.1415926)\n",
    "    liblist=np.asarray(liblist)\n",
    "    thresh_contour = liblist[spatial.ConvexHull(liblist).vertices]\n",
    "    return thresh_contour\n",
    "def Extract_Protein(\n",
    "    picdir,thresh_contour,\n",
    "    outdir='test',\n",
    "    cviter=3,\n",
    "    picave=3,\n",
    "    diiter=3,\n",
    "    thresh_adt=0.35,\n",
    "    thresh_pick=0.1,\n",
    "    kernalsize_adt=(25,25),\n",
    "    kernalsize_filter=(5,5),\n",
    "    avekernal=[0.25,0.5,0.25],\n",
    "    listthresh=30\n",
    "    ):\n",
    "    os.mkdir(outdir+'/binary')\n",
    "    os.mkdir(outdir+'/ori')\n",
    "#################################################################################\n",
    "    extended_contour=np.zeros((thresh_contour.shape[0]+1,thresh_contour.shape[1]))\n",
    "    extended_contour[:-1,:]=thresh_contour\n",
    "    avekernal=np.asarray(avekernal)\n",
    "    avecenter=avekernal.argmax()\n",
    "    dirlist=os.listdir(picdir)\n",
    "    pinserie=[]\n",
    "    contourlist=[]\n",
    "    print(thresh_contour)\n",
    "    hullarea=spatial.ConvexHull(thresh_contour).volume\n",
    "    for i,p in enumerate(dirlist):\n",
    "        pinframe=[i+avecenter,dirlist[i+avecenter]]\n",
    "        if i>=(len(dirlist)-picave):\n",
    "            break\n",
    "        ave=0\n",
    "        ori=cv.imread(picdir+'/'+dirlist[i+avecenter],flags=cv.CV_8U)\n",
    "        for j in range(picave):\n",
    "            ave=ave+cv.imread(picdir+'/'+dirlist[i+j],flags=cv.CV_8U)*avekernal[j]\n",
    "        burr=cv.GaussianBlur(ave.astype('uint8'), kernalsize_filter, 0)\n",
    "        bi_gray= (255-AdaptiveThresh(burr,kernalsize_adt,thresh_adt)).astype('uint8')\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (3, 3))\n",
    "        bi_gray = cv.morphologyEx(bi_gray, cv.MORPH_OPEN, kernel,iterations=cviter)\n",
    "        bi_gray = cv.morphologyEx(bi_gray, cv.MORPH_CLOSE, kernel,iterations=cviter)\n",
    "        cv.imwrite(outdir+'/binary/'+dirlist[i+avecenter],bi_gray)\n",
    "        contours, hierarchy = cv.findContours(bi_gray.astype('uint8'), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        outpic=ave.copy()\n",
    "#        tempmask=np.zeros(ave.shape,dtype='uint8')\n",
    "        pcounts=0\n",
    "        for c, contour in enumerate(contours):\n",
    "            # print(i)\n",
    "#            print(contour)\n",
    "            Area = cv.contourArea(contour)\n",
    "            if Area==0:\n",
    "                continue\n",
    "#            circle=cv.arcLength(contour, True)\n",
    "            contour_r=contour.reshape(contour.size//2,2)\n",
    "            maxdist=spatial.distance_matrix(contour_r, contour_r).max()\n",
    "            extended_contour[-1]=np.asarray([Area,maxdist])\n",
    "            para_pick=spatial.ConvexHull(extended_contour).volume-hullarea\n",
    "            if Area>=50:\n",
    "                contourlist.append([p,c,Area,maxdist,contour.mean(axis=0)[0][0],contour.mean(axis=0)[0][1],para_pick])\n",
    "            if para_pick<thresh_pick:\n",
    "                cv.drawContours(ori,contours,c,255,1)\n",
    "                pinframe.append([contour.mean(axis=0)[0],contour])\n",
    "                pcounts+=1\n",
    "        pinserie.append(pinframe)\n",
    "#        print('found ',pcounts,' in pic ',dirlist[i+avecenter])    \n",
    "#        tempmask=cv.dilate(tempmask,kernel=kernel,iterations=3)\n",
    "#        masked=(tempmask/255*(255-cv.imread(picdir+'/'+dirlist[i+avecenter],flags=cv.CV_8U))).astype('uint8')\n",
    "        cv.imwrite(outdir+'/ori/'+dirlist[i+avecenter],ori)\n",
    "    pd.DataFrame(contourlist,columns=['name','id','area','circle','x','y','para_dist']).to_csv(outdir+'/contour.csv')\n",
    "    return pinserie\n",
    "def Particle_clustering(pinserie,minobserve,maxmissing=15,maxdrift=7.0):\n",
    "    plist=[]\n",
    "    protein=[]\n",
    "#pinserie saved as [[frame,filename,[center1,contour1],[center2,contour2]...]...]\n",
    "#clustered protein saved as [[frame1,filename1,center1,contour1], [frame2,filename2,center2,contour2], [frame3,filename3,center3,contour3]...] \n",
    "    while len(pinserie)>0:\n",
    "#        print(len(pinserie),pinserie[0],len(pinserie[0]))\n",
    "        while len(pinserie[0])==2:\n",
    "            pinserie.pop(0)\n",
    "            if len(pinserie)==0:\n",
    "                if len(protein)>=minobserve:\n",
    "                    print('protein ',len(plist),'detected in ',len(protein),' frames')\n",
    "                    plist.append(protein)\n",
    "#                print('all protein detected')\n",
    "                return plist\n",
    "        protein=[[pinserie[0][0],pinserie[0][1],pinserie[0][2][0],pinserie[0][2][1]]]\n",
    "        print('protein',len(plist),' detected at frame ',protein[-1][0],' centered at ',protein[-1][2])\n",
    "        pinserie[0].pop(2)\n",
    "        missedframe=1\n",
    "        for pl in pinserie[1:]:\n",
    "#            print(pl[0],len(pl))\n",
    "            for pi in range(2,len(pl)):\n",
    "#protein drift less than sqrt(maxdrift*missingframes) been considered as series\n",
    "                if ((protein[-1][2]-pl[pi][0])**2).sum() <missedframe*maxdrift*maxdrift:\n",
    "#                    print('find protein',len(plist),' at frame ',pl[0],'centered at',pl[pi][0],'after ',missedframe,' frames')\n",
    "                    protein.append([pl[0],pl[1],pl[pi][0],pl[pi][1]])\n",
    "                    pl.pop(pi)\n",
    "                    missedframe=0\n",
    "                    break\n",
    "            missedframe+=1\n",
    "            if missedframe>=maxmissing:\n",
    "                break\n",
    "        if len(protein)>=minobserve:\n",
    "            print('protein ',len(plist),'detected in ',len(protein),' frames')\n",
    "            plist.append(protein)\n",
    "    return plist\n",
    "def Gen_picked_pic(plist,dirin,outdir,\n",
    "                   kernel=cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5)),dilate_iter=3,picsize=[35,35],\n",
    "                   debug=True):\n",
    "    count=0\n",
    "    dirlist=[]\n",
    "    drifts=[]\n",
    "    for i in plist:\n",
    "        count+=1\n",
    "        os.mkdir(outdir+'/protein_'+str(count))\n",
    "        os.mkdir(outdir+'/ori_'+str(count))\n",
    "#        print(os.system('mkdir '+tempdir+'_'+str(count)),'mkdir '+tempdir+'_'+str(count))\n",
    "        dirlist.append(outdir+'/protein_'+str(count))\n",
    "        drift=[]\n",
    "        for c in i:\n",
    "#            print(c[1],c[3])\n",
    "            ori_pic=cv.imread(dirin+'/'+c[1],flags=cv.CV_8U)\n",
    "            mask=np.zeros(ori_pic.shape,dtype='uint8')\n",
    "            cv.drawContours(mask,(c[3],),0,255,cv.FILLED)\n",
    "            mask=cv.dilate(mask,kernel=kernel,iterations=dilate_iter)\n",
    "            masked=(mask/255*(255-ori_pic))\n",
    "            masked[masked==0]=255-ori_pic.mean()\n",
    "     #       masked=masked.astype('uint8')\n",
    "            pos=[int(c[2][0]),int(c[2][1])]\n",
    "            cutted=masked[max(0,pos[1]-picsize[1]):min(ori_pic.shape[1],pos[1]+picsize[1]),max(0,pos[0]-picsize[0]):min(ori_pic.shape[0],pos[0]+picsize[0])].astype('uint8')\n",
    "            cutted_ori=ori_pic[max(0,pos[1]-picsize[1]):min(ori_pic.shape[1],pos[1]+picsize[1]),max(0,pos[0]-picsize[0]):min(ori_pic.shape[0],pos[0]+picsize[0])].astype('uint8')\n",
    "            cv.drawContours(ori_pic,(c[3],),0,255,1)\n",
    "            drift.append((max(0,pos[1]-picsize[1]),max(0,pos[0]-picsize[0])))\n",
    "            cv.imwrite(outdir+'/ori_'+str(count)+'/'+c[1],cutted_ori)\n",
    "            cv.imwrite(outdir+'/protein_'+str(count)+'/'+c[1],cutted)\n",
    "        drifts.append(drift)\n",
    "    return dirlist,drifts\n",
    "def average_pic(picdir='2',ave=5,outdir='pic_average'):\n",
    "    dirlist=os.listdir(picdir)\n",
    "    os.system('mkdir '+outdir)\n",
    "    frames=[]\n",
    "    summary=0\n",
    "    for i in range(ave):\n",
    "        frames.append(mpimg.imread(picdir+'/'+dirlist[i]))\n",
    "        summary=frames[i]+summary\n",
    "        mpimg.imsave(outdir+'/0.png',summary/ave)\n",
    "    count=0\n",
    "    for i in range(ave,len(dirlist)):\n",
    "        if count>=ave:\n",
    "            count=0\n",
    "        frames[count]=mpimg.imread(picdir+'/'+dirlist[i])\n",
    "        mpimg.imsave(outdir+'/'+str(i-ave+1)+'.png',summary/ave)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a04afc59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T02:10:24.757160Z",
     "start_time": "2022-07-05T02:10:24.730126Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def makegif(fits,oridir,picdir,outdir,fit_shape,duration=0.3,level=50,cmap=cv.COLORMAP_JET):\n",
    "#when fits==0 write gif for original pictures\n",
    "    pics=os.listdir(picdir)\n",
    "    os.mkdir(outdir)\n",
    "    oriframes=[]\n",
    "    simframes=[]\n",
    "    for i in pics:\n",
    "#        fit_shape=fits[i][0].shape\n",
    "        oriframe=cv.imread(oridir+'/'+i)\n",
    "        croped_pic=255-cv.imread(picdir+'/'+i)\n",
    "        simframe=np.zeros(croped_pic.shape).astype('uint8')\n",
    "        if oriframe.shape!=simframe.shape:\n",
    "            print('hahaha')\n",
    "            continue\n",
    "        picshape=oriframe.shape\n",
    "        if type(fits[i][0])==int or not i in fits:\n",
    "            oriframes.append(oriframe)\n",
    "            simframes.append(simframe)\n",
    "            continue\n",
    "        ys=fits[i][2]-fit_shape[1]\n",
    "        xs=fits[i][1]-fit_shape[0]\n",
    "        fm=fits[i][0].max()\n",
    "        pic0=croped_pic[0,0,0]\n",
    "        protein_mask=croped_pic[:,:,0][croped_pic[:,:,0]!=pic0]\n",
    "        p_max=protein_mask.max()\n",
    "        p_min=protein_mask.min()\n",
    "        gray=(croped_pic-p_min).astype('float32')*255/(p_max-p_min)\n",
    "        orifc=cv.applyColorMap(gray.astype('uint8'),cmap)\n",
    "        for y in range(picshape[0]):\n",
    "            for x in range(picshape[1]):\n",
    "                if croped_pic[y,x,0]!=pic0:\n",
    "                    oriframe[y,x]=orifc[y,x]\n",
    "#        print(fits[i][0]>0.001)\n",
    "#        op=np.zeros(pic.shape).astype('uint8')\n",
    "#        op[:,:,0][pic[:,:,0]!=pic0]=255-protein_mask\n",
    "#        op[:,:,1][pic[:,:,0]!=pic0]=(protein_mask)/3\n",
    "#        op[:,:,2][pic[:,:,0]!=pic0]=(protein_mask)/1\n",
    "#        oriframe[]\n",
    "#        oriframe[fits[i][2]-len(fits[i][0]):fits[i][2],fits[i][1]-len(fits[i][0][0]):fits[i][1],:]=op\n",
    "        oriframes.append(oriframe)\n",
    "        print(i)\n",
    "        template=(255-fits[i][0]*255/fm).astype('uint8')\n",
    "        simfc=cv.applyColorMap(template,cmap)\n",
    "        z=np.asarray([128,0,0]).astype('uint8')\n",
    "        for x in range(fit_shape[0]):\n",
    "            for y in range(fit_shape[1]):\n",
    "                if template[y,x]<255:\n",
    "                    simframe[fits[i][2]-len(fits[i][0])+y,fits[i][1]-len(fits[i][0][0])+x]=simfc[y,x]\n",
    "#        print(fits[i][2]-len(fits[i][0]),fits[i][2],fits[i][1]-len(fits[i][0][0]),fits[i][1],simfc.shape)\n",
    "#        simframe[fits[i][2]-len(fits[i][0]):fits[i][2],fits[i][1]-len(fits[i][0][0]):fits[i][1],:]=simfc\n",
    "#        simframe[simframe[:,:,0]==0]=simfc[simframe[:,:,0]==0]\n",
    "        print(oriframe.shape,simframe.shape,oriframe.dtype,simframe.dtype)\n",
    "        simframes.append(simframe)\n",
    "        cv.imwrite(outdir+'/ori_'+i+'.png',cv.cvtColor(oriframe,cv.COLOR_RGB2BGR))\n",
    "        cv.imwrite(outdir+'/sim_'+i+'.png',cv.cvtColor(simframe,cv.COLOR_RGB2BGR))\n",
    "    imageio.mimsave(outdir+'_ori.gif', oriframes, 'GIF', duration=duration)\n",
    "    imageio.mimsave(outdir+'_fitted.gif', simframes, 'GIF', duration=duration)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1bb87d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T02:46:44.995675Z",
     "start_time": "2022-07-05T02:46:44.947681Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cvmatch(lib,pic,drift,ori=0,r=10,method=cv.TM_CCOEFF_NORMED):\n",
    "#def cvmatch(lib,pic,ori=0,r=10,method=cv.TM_CCORR_NORMED):\n",
    "#def cvmatch(lib,pic,ori=0,r=10,method=cv.TM_CCORR):\n",
    "\n",
    "#    tempic=(mpimg.imread(pic).mean()-mpimg.imread(pic)).astype('uint8')\n",
    "#    inpic=cv.imread(pic,cv.CV_8U)[323:366,385:424].astype('float32')\n",
    "#    inpic=cv.imread(pic,cv.CV_8U)[270:372,425:517].astype('float32')\n",
    "    tempic=cv.imread(pic,cv.CV_8U).astype('float32')\n",
    "#    tempic=extract_protein(inpic)\n",
    "    bestfit=[0,0,0,0,0,0,0]\n",
    "    cvlib=lib\n",
    "    scores=[]\n",
    "    drifts=[]\n",
    "#    for p in lib:\n",
    "#        cvlib[p]=(lib[p].astype('float32'))\n",
    "    for p in cvlib.index:\n",
    "        i=cvlib.pic[p]\n",
    "        cmatch=cv.matchTemplate(tempic,i,method)\n",
    "        m=cmatch.argmax()\n",
    "        l=len(cmatch[0])\n",
    "# normalized TMCCORR\n",
    "#        score=2*cmatch.max()/((i*i).sum()+(tempic[int(m//l):int(m//l)+i.shape[0],m%l:m%l+i.shape[1]]*tempic[int(m//l):int(m//l)+i.shape[0],m%l:m%l+i.shape[1]]).sum())\n",
    "        score=cmatch.max()\n",
    "        scores.append(score)\n",
    "        drifts.append([m%l+i.shape[1],int(m//l)+i.shape[0]])\n",
    "    return drifts,np.asarray(scores)\n",
    "def extract_best(scores,libshape,ntops=5):\n",
    "    score_t=scores.reshape(libshape[1],libshape[0])\n",
    "    output=[]\n",
    "    for pid,score_l in enumerate(score_t):\n",
    "        top_index=np.argpartition(score_l, -ntops)[-ntops:]\n",
    "        for i in top_index:\n",
    "            output.append([pid,i,score_l[i]])\n",
    "    return(np.asarray(output))\n",
    "def autosearch(picdir,template,\n",
    "               outdir='fitted',debug=True,\n",
    "               quatfile='lib/c48u27.quat',resolution=3.7,rf=10,pick=[],\n",
    "               libmol='lib/mol.csv',iscg=0,picsize=0,thresh_pick=0.01,\n",
    "               minobserve=100,thresh_adt=0.35,ntops=1):\n",
    "    dirlist=os.listdir(picdir)\n",
    "    os.mkdir(outdir)\n",
    "    if type(template)==str:\n",
    "        lib,size=genlib(template,quatfile,resolution=resolution,iscg=iscg,libmol=libmol,size=picsize)\n",
    "        picsize=[size,size]\n",
    "        print('lib generated')\n",
    "        thresh_contour=gen_Morph_parameter(lib)\n",
    "    elif type(template)==pd.DataFrame:\n",
    "        lib=template\n",
    "        print('use input lib')\n",
    "        picsize=lib.pic[0].shape\n",
    "        thresh_contour=gen_Morph_parameter(lib)\n",
    "    else:\n",
    "        raise ValueError('input lib must be a folder contains pdb files or a libary generated by genlib')\n",
    "    if len(pick)==3:\n",
    "#            thresh_contour=np.asarray([[pick[0]*pick[1]*np.pi/(4*resolution),max(pick[0],pick[1])],\n",
    "#                                       [pick[2]*pick[1]*np.pi/(4*resolution),max(pick[2],pick[1])],\n",
    "#                                       [pick[0]*pick[2]*np.pi/(4*resolution),max(pick[0],pick[2])],])/resolution\n",
    "            thresh_contour=np.asarray([[pick[0]*pick[1]/(resolution),np.sqrt(pick[0]*pick[0]+pick[1]*pick[1])],\n",
    "                                       [pick[2]*pick[1]/(resolution),np.sqrt(pick[2]*pick[2]+pick[1]*pick[1])],\n",
    "                                       [pick[0]*pick[2]/(resolution),np.sqrt(pick[0]*pick[0]+pick[2]*pick[2])],])/resolution\n",
    "            print('pick particles with length: ',template)\n",
    "    print('pick range generated')\n",
    "    pinserie=Extract_Protein(picdir,thresh_contour,outdir=outdir,thresh_adt=thresh_adt,thresh_pick=thresh_pick)\n",
    "    print('contours found')    \n",
    "    plist=Particle_clustering(pinserie,minobserve,maxmissing=30,maxdrift=7)\n",
    "    print('particle clustered')\n",
    "    picked_dirlist,drifts=Gen_picked_pic(plist,picdir,outdir=outdir,\n",
    "                                         kernel=cv.getStructuringElement(cv.MORPH_ELLIPSE, (3, 3)),dilate_iter=3,picsize=picsize)\n",
    "    print('picked picture generated')\n",
    "    summary=pd.DataFrame({'pic':[],'protein_id':[],'pdb':[],'score':[],'qr':[],'qi':[],'qj':[],'qk':[],'dx':[],'dy':[]},index=[])\n",
    "    pdblist=lib['pdb'].unique()\n",
    "    libshape=[int(len(lib)/len(pdblist)),len(pdblist)]\n",
    "    qlist=lib['q'][0:libshape[0]]\n",
    "    for pc,protein in enumerate(picked_dirlist):\n",
    "        fits={}\n",
    "        dirlist_pro=os.listdir(protein)\n",
    "        list_score=np.zeros([len(dirlist_pro),len(lib)])\n",
    "        for c,i in enumerate(dirlist_pro):\n",
    "            pic_summary=pd.DataFrame({'pic':[],'protein_id':[],'pdb':[],'score':[],'qr':[],'qi':[],'qj':[],'qk':[],'dx':[],'dy':[]},index=[])\n",
    "            drift,list_score[c]=cvmatch(lib,protein+'/'+i,drifts[pc][c])\n",
    "            outdata=extract_best(list_score[c],libshape,ntops)\n",
    "            for out in outdata:\n",
    "#               print(qlist[out[1]])\n",
    "#                for n in range(len(out)):\n",
    "#                print(out)\n",
    "                pic_summary=pic_summary.append(pd.DataFrame({'pic':c,'protein_id':pc,'pdb':pdblist[int(out[0])],'score':out[2],\n",
    "                                                     'qr':qlist[out[1]][0].item(),'qi':qlist[out[1]][1].item(),'qj':qlist[out[1]][2].item(),'qk':qlist[out[1]][3].item(),\n",
    "                                                     'dx':drift[int(out[0]*libshape[1]+out[1])][1],'dy':drift[int(out[0]*libshape[1]+out[1])][0]},index=[0]),ignore_index=True)\n",
    "#                print(outdata)\n",
    "            best_index=pic_summary.score.argmax()\n",
    "#            print(pic_summary.dx[best_index])\n",
    "            fit=[0,pic_summary.dx[best_index],pic_summary.dy[best_index],pic_summary.score[best_index],\n",
    "                 pic_summary.pdb[best_index]]\n",
    "            summary=summary.append(pic_summary,ignore_index=True)\n",
    "            fits[i]=fit\n",
    "            print('protein '+protein+' in picture',i,'is fitted as',fit[4],'fitted score:',fit[3])\n",
    "        makegif(fits,outdir+'/ori_'+str(pc+1),outdir+'/protein_'+str(pc+1),outdir+'/protein_'+str(pc+1)+'pics',picsize)\n",
    "        print('gif for protein '+str(pc+1)+' saved as '+outdir+'/protein_'+str(pc+1)+'movie.gif')\n",
    "        table_score=pd.DataFrame(list_score)\n",
    "        table_score.index=dirlist_pro\n",
    "        table_score.to_csv(outdir+'/protein_'+str(pc+1)+'.csv')\n",
    "#        makegif(0,outdir+'/ori_'+str(pc+1),outdir+'/protein_'+str(pc+1)+'ori.gif')\n",
    "    summary.to_csv(outdir+'/summary.csv')\n",
    "    return summary\n",
    "def drawcmatch(pdblib='GAPRPDB',lib='',picdir='2',outname='sim.gif',ang=5,libgrid='std60.csv',\n",
    "         resolution=3.7,rf=10,oriout='',libmol='mol.csv',iscg=0,picaver=0):\n",
    "    if picaver:\n",
    "        os.system('mkdir TEMPPIC')\n",
    "        average_pic(picdir,ave=picaver,outdir='TEMPPIC')\n",
    "        picdir='TEMPPIC'\n",
    "    if lib:\n",
    "        print('use input lib')\n",
    "    else:\n",
    "        lib=genlib(pdblib,libgrid,ang,resolution=resolution,iscg=iscg,libmol=libmol)\n",
    "        print('lib generated')\n",
    "    cmatch=[]\n",
    "    dirlist=os.listdir(picdir)\n",
    "    for i in dirlist:\n",
    "        cmatch.append(cvmatch(lib,picdir+'/'+i))\n",
    "    print('gif saved as ',outname)\n",
    "    return cmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "370d65a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T02:46:58.342614Z",
     "start_time": "2022-07-05T02:46:48.981448Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/7416 [00:00<?, ?it/s]<ipython-input-14-d39382a9d121>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  atom_x=torch.tensor((pos[:,0]+drift[0])/resolution,dtype=torch.int32)#.type(torch.ShortTensor)\n",
      "<ipython-input-14-d39382a9d121>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  atom_y=torch.tensor((pos[:,1]+drift[1])/resolution,dtype=torch.int32)#.type(torch.ShortTensor)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7416/7416 [00:14<00:00, 517.86it/s]\n"
     ]
    }
   ],
   "source": [
    "libecori,size=genlib(pdblib='PDBfiles/state228',quatfile='lib/c48u309.quat',resolution=0.5,iscg=1,libmol='lib/sirah2-liu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4baa3ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use input lib\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'maxdist' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e6be3b66c6b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfits_ecori\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautosearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpicdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'simulated_data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlibecori\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mminobserve\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthresh_adt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthresh_pick\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-fe10b804b387>\u001b[0m in \u001b[0;36mautosearch\u001b[1;34m(picdir, template, outdir, debug, quatfile, resolution, rf, pick, libmol, iscg, picsize, thresh_pick, minobserve, thresh_adt, ntops)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'use input lib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mpicsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mthresh_contour\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgen_Morph_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'input lib must be a folder contains pdb files or a libary generated by genlib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-9492537f5274>\u001b[0m in \u001b[0;36mgen_Morph_parameter\u001b[1;34m(lib, kernalsize_filter, thresh, appsize, cviter)\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mmaxdist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontour_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontour_r\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m#        liblist.append([largest,circle])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mliblist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlargest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxdist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;31m#        print(largest,circle*circle/(largest*4*3.1415926))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m#        maxcd=circle*circle/(largest*4*3.1415926)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'maxdist' referenced before assignment"
     ]
    }
   ],
   "source": [
    "fits_ecori=autosearch(picdir='simulated_data',template=libecori,outdir='test1',rf=10,minobserve=1,thresh_adt=0.15,debug=True,thresh_pick=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbccf89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
